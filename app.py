import datetime
import streamlit as st
from langchain.llms import openai
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores.chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate


# í•¨ìˆ˜ ì •ì˜

## txtíŒŒì¼ ìë¥´ê¸° ë¦¬í„´ê°’: ìƒˆë¡œìš´ txtíŒŒì¼
def cut_and_search_target_date(content):
    current_date = datetime.datetime.now()
    target_date = current_date - datetime.timedelta(days=1)

    while target_date >= current_date - datetime.timedelta(days=30):  # ì˜ˆë¥¼ ë“¤ì–´, ìµœëŒ€ 30ì¼ ì „ê¹Œì§€ ê²€ìƒ‰
        target_date_str = target_date.strftime("%Yë…„ %mì›” %dì¼")  # ë‚ ì§œ í˜•ì‹ì€ íŒŒì¼ì— ë§ì¶° ì¡°ì •
        if target_date_str in content:
            start_index = content.index(target_date_str)
            return content[start_index:]
        target_date -= datetime.timedelta(days=1)

    return None  # 30ì¼ ë‚´ì— ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° None ë°˜í™˜


## new contentë¥¼ ë²¡í„°í™”í•˜ê¸°

def new_content_data(content):
    if content is not None:
        # new_content ì²˜ë¦¬
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = text_splitter.create_documents(new_content)
        if texts:
            texts = text_splitter.create_documents(content)
            # Select embeddings
            embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
            # Create a vectorstore from documents
            db = Chroma.from_documents(texts, embeddings)
        else:
            st.warning("ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ì›í•˜ëŠ” ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return db

## ìë™ë‹µë³€
def first_reply(db):
    chattingroom=chattingroom
    content=content
    prompt = PromptTemplate(input_variables=["subject"],
    template=f"""
        ë‹¹ì‹ ì€ ì§€ê¸ˆë¶€í„° ëŒ€í™” ë‚´ìš© ì •ë¦¬ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì´ íŒŒì¼ì€ {chattingroom}ì´ë¼ëŠ” ì±„íŒ…ë°©ì˜ ê¸°ë¡ì…ë‹ˆë‹¤.
        í•´ë‹¹ ì±„íŒ…ë°©ì—ì„œëŠ” ì£¼ë¡œ {content}ì„ ì£¼ì œë¡œ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.
        í•´ë‹¹ txt íŒŒì¼ì„ ë‹¤ìŒì˜ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”:
        ---
        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸/í†µì°°ì  
        ê´€ë ¨í•´ì„œ ê°€ì¥ ë§ì€ ì–¸ê¸‰ì´ ë§ì•˜ë˜ ì£¼ì œ 5ê°€ì§€ë¥¼ bulletìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
        # ì–¸ê¸‰ë˜ì—ˆë˜ URL ëª¨ìŒ
        ìµœì†Œ 5ê°œì˜ ë§í¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. 
        'ë§í¬' - 'ë§í¬ì— ëŒ€í•œ ì„¤ëª…' í˜•ì‹ìœ¼ë¡œ ì ì–´ì£¼ì„¸ìš”. 
        --- 
        ì‚¬ìš©ìê°€ ì¶”ê°€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ txt íŒŒì¼ ë‚´ì˜ ì§€ì‹ì„ ì´ìš©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
        """),
    return prompt.format(subject=db)
    


##ì¶”ê°€ì§ˆì˜ìš©
def generate_response(db, query_text):
    # Create retriever interface
    retriever = db.as_retriever()
    # Create QA chain
    qa = RetrievalQA.from_chain_type(llm=openai(openai_api_key=openai_api_key), chain_type='stuff', retriever=retriever)
    return qa.run(query_text)   



# ì—¬ê¸°ì„œë¶€í„°ëŠ” ì¸í„°í˜ì´ìŠ¤(streamlit)
## íƒ€ì´í‹€
st.title("ğŸ— ì˜¤í”ˆ ì±„íŒ…ë°©ì˜ í•˜ë£¨ì¹˜ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.")

## ì—…ë¡œë“œ íŒŒì¼
uploaded_file = st.file_uploader('ì¹´ì¹´ì˜¤í†¡ txtíŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.', type='txt')


## ì±„íŒ…ë°© ì´ë¦„, ì£¼ì œ, API í‚¤ ì…ë ¥ì¹¸
with st.form('í¼1', clear_on_submit=True):
    chattingroom = st.text_input('ì±„íŒ…ë°© ì´ë¦„', type='default')
    content = st.text_input('ì±„íŒ…ë°©ì˜ ì£¼ì œë¥¼ ì ì–´ì£¼ì„¸ìš”. ex. ì£¼ì‹', type='default')
    openai_api_key = st.text_input('OpenAI API Key', type='password')
    submitted = st.form_submit_button('ì…ë ¥')

    #ì…ë ¥í–ˆì„ ê²½ìš° 1. txtíŒŒì¼ ìë¥´ê¸° 2. txtíŒŒì¼ ë²¡í„° dbë¡œ ë³€í™˜í›„ ì €ì¥ 3. ì²«ë²ˆì§¸ ë‹µë³€
    if submitted and openai_api_key.startswith('sk-'):
        with st.spinner('ì±„íŒ…ë°©ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìš”ì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤.'):
            if uploaded_file is not None:
                # íŒŒì¼ ë‚´ìš© ì½ê¸°
                file_contents = uploaded_file.read().decode("utf-8", errors="ignore")
                new_content = cut_and_search_target_date(file_contents)
                #ì¼ë‹¨ ì—¬ê¸°ê¹Œì§„ ì„±ê³µ... ê·¼ë° ì´ ë’¤ë¶€í„° ë¬´í•œëŒ€ê¸°ì„ ã„·
                db = new_content_data(new_content)
                print(first_reply(db))
                

# # Query text
# query_text = st.text_input('ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°:', placeholder = 'Xì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì•Œë ¤ì¤˜', disabled=not uploaded_file)


# # Form input and query
# result = []
# with st.form('í¼2', clear_on_submit=True):
#     submitted = st.form_submit_button('ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°', disabled=not(uploaded_file and query_text))
#     if submitted:
#         with st.spinner('ì§ˆë¬¸ì¤‘...'):
#             response = generate_response(db=db, query_text=query_text)
#             result.append(response)
#             del openai_api_key

# if len(result):
#     st.info(response)



# # ì—†ì–´ë„ ë˜ëŠ”ê±°
# st.sidebar.title("About")
# st.sidebar.info(
#     "ì˜¤í”ˆì±„íŒ…ë°© í•µì‹¬ ë‚´ìš©ë§Œ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤."
# )