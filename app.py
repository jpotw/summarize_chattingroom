import datetime
import os
from delete import make_new_file
import streamlit as st
from langchain.llms import openai
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores.chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv



#API í‚¤ ì„¸íŒ…
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")


# í•¨ìˆ˜ ì •ì˜
## new contentë¥¼ ë²¡í„°í™”í•´ì„œ DBì— ì €ì¥
def new_content_doc(new_file):
    if new_file is not None:
        # new_content ì²˜ë¦¬
        text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
        texts = text_splitter.create_documents(new_file)
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        # Create a vectorstore from documents
        db = Chroma.from_documents(texts, embeddings)
    else:
        st.warning("ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return db


## ì²«ë²ˆì§¸ ëŒ€ë‹µ return: response based on prompt
def first_answer(chattingroom, content, db):
    # Create your custom prompt using the provided chattingroom and content
    custom_prompt = f"""
    ë‹¹ì‹ ì€ ì§€ê¸ˆë¶€í„° ëŒ€í™” ë‚´ìš© ì •ë¦¬ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    {db}ëŠ” "{chattingroom}"ì´ë¼ëŠ” ì±„íŒ…ë°©ì˜ ê¸°ë¡ì…ë‹ˆë‹¤.

    í•´ë‹¹ ì±„íŒ…ë°©ì—ì„œëŠ” ì£¼ë¡œ "{content}"ì„ ì£¼ì œë¡œ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.

    í•´ë‹¹ txt íŒŒì¼ì„ ë‹¤ìŒì˜ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”:

    ---

    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸/í†µì°°ì 

    ê´€ë ¨í•´ì„œ ê°€ì¥ ë§ì€ ì–¸ê¸‰ì´ ë§ì•˜ë˜ ì£¼ì œ 5ê°€ì§€ë¥¼ bulletìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.

    # ì–¸ê¸‰ë˜ì—ˆë˜ URL ëª¨ìŒ

    ìµœì†Œ 5ê°œì˜ ë§í¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

    'ë§í¬' - 'ë§í¬ì— ëŒ€í•œ ì„¤ëª…' í˜•ì‹ìœ¼ë¡œ ì ì–´ì£¼ì„¸ìš”.

    ---

    ì‚¬ìš©ìê°€ ì¶”ê°€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ txt íŒŒì¼ ë‚´ì˜ ì§€ì‹ì„ ì´ìš©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
    """

    # Use LangChain's OpenAI interface to send the prompt
    response = openai(custom_prompt, temperature=0, api_key=openai_api_key)

    return response


##ì¶”ê°€ì§ˆì˜ìš©
def generate_response(db, query_text):
    # Create retriever interface
    retriever = db.as_retriever()
    # Create QA chain
    qa = RetrievalQA.from_chain_type(llm=openai(openai_api_key=openai_api_key), chain_type='stuff', retriever=retriever)
    return qa.run(query_text)   

## í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë‹µë³€ì´ìš”

def openai_response(prompt):
    openai.ChatCompletion.create(
                model="text-davinci-003",  # ëª¨ë¸ì„ ì§€ì •í•˜ì„¸ìš”. ì˜ˆ: "text-davinci-003"
                prompt=prompt
                )

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ì¶œë ¥
    print(response.choices[0].text)


# ì—¬ê¸°ì„œë¶€í„°ëŠ” ì¸í„°í˜ì´ìŠ¤(streamlit)
## íƒ€ì´í‹€
st.title("ğŸ— ì˜¤í”ˆ ì±„íŒ…ë°©ì˜ í•˜ë£¨ì¹˜ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.")


uploaded_file = st.file_uploader('ì¹´ì¹´ì˜¤í†¡ txtíŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.', type='txt')

if uploaded_file is not None:
    with st.spinner('íŒŒì¼ì„ ìë¥´ëŠ” ì¤‘ì…ë‹ˆë‹¤.'):
        new_file = make_new_file(uploaded_file)
        st.write("íŒŒì¼ì„ ì˜ëìŠµë‹ˆë‹¤.")
else:
    st.error("ì•„ì§ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


## ì±„íŒ…ë°© ì´ë¦„, ì£¼ì œ, API í‚¤ ì…ë ¥ì¹¸
with st.form('í¼1', clear_on_submit=True):
    chattingroom = st.text_input('ì±„íŒ…ë°© ì´ë¦„', type='default')
    content = st.text_input('ì±„íŒ…ë°©ì˜ ì£¼ì œë¥¼ ì ì–´ì£¼ì„¸ìš”. ex. ì£¼ì‹', type='default')
    # openai_api_key = st.text_input('OpenAI API Key', type='password')
    submitted = st.form_submit_button('ì…ë ¥')
    if submitted:
        new_content_doc(new_file)
        first_answer(chattingroom=chattingroom, content=content)


    result=[]
    result.append(first_answer)

                

# Query text
query_text = st.text_input('ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°:', placeholder = 'Xì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì•Œë ¤ì¤˜', disabled=not uploaded_file)


# Form input and query
with st.form('í¼2', clear_on_submit=True):
    submitted = st.form_submit_button('ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°', disabled=not(uploaded_file and query_text))
    if submitted:
        with st.spinner('ì§ˆë¬¸ì¤‘...'):
            response = generate_response(db=db, query_text=query_text)
            result.append(response)
            del openai_api_key

if len(result):
    st.info(response)



# ì—†ì–´ë„ ë˜ëŠ”ê±°
st.sidebar.title("About")

st.sidebar.info(
        "ì¹´ì¹´ì˜¤í†¡ ë‚´ìš© ìš”ì•½í•´ë“œë¦¼"
    )